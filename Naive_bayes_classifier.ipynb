{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHgKuqyYzFCszXDEjIrn/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christina-26/Marvel-tasks-level-1/blob/main/Naive_bayes_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsSGP-0R3gn",
        "outputId": "d8ac7eef-9b9d-4587-e21a-3c33c54f20d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of examples are:  777\n",
            "Out of these, training examples are:  543\n",
            "Test examples are:  234\n",
            "Accuracy of your model is:  0.0\n"
          ]
        }
      ],
      "source": [
        "# Importing library\n",
        "import math\n",
        "import random\n",
        "import csv\n",
        "\n",
        "\n",
        "# the categorical class names are changed to numberic data\n",
        "# eg: yes and no encoded to 1 and 0\n",
        "def encode_class(mydata):\n",
        "\tclasses = []\n",
        "\tfor i in range(len(mydata)):\n",
        "\t\tif mydata[i][-1] not in classes:\n",
        "\t\t\tclasses.append(mydata[i][-1])\n",
        "\tfor i in range(len(classes)):\n",
        "\t\tfor j in range(len(mydata)):\n",
        "\t\t\tif mydata[j][-1] == classes[i]:\n",
        "\t\t\t\tmydata[j][-1] = i\n",
        "\treturn mydata\n",
        "\n",
        "\n",
        "# Splitting the data\n",
        "def splitting(mydata, ratio):\n",
        "\ttrain_num = int(len(mydata) * ratio)\n",
        "\ttrain = []\n",
        "\t# initially testset will have all the dataset\n",
        "\ttest = list(mydata)\n",
        "\twhile len(train) < train_num:\n",
        "\t\t# index generated randomly from range 0\n",
        "\t\t# to length of testset\n",
        "\t\tindex = random.randrange(len(test))\n",
        "\t\t# from testset, pop data rows and put it in train\n",
        "\t\ttrain.append(test.pop(index))\n",
        "\treturn train, test\n",
        "\n",
        "\n",
        "# Group the data rows under each class yes or\n",
        "# no in dictionary eg: dict[yes] and dict[no]\n",
        "def groupUnderClass(mydata):\n",
        "\tdict = {}\n",
        "\tfor i in range(len(mydata)):\n",
        "\t\tif (mydata[i][-1] not in dict):\n",
        "\t\t\tdict[mydata[i][-1]] = []\n",
        "\t\tdict[mydata[i][-1]].append(mydata[i])\n",
        "\treturn dict\n",
        "\n",
        "\n",
        "# Calculating Mean\n",
        "def mean(numbers):\n",
        "\treturn sum(numbers) / float(len(numbers))\n",
        "\n",
        "# Calculating Standard Deviation\n",
        "def std_dev(numbers):\n",
        "  if len(numbers) < 2:\n",
        "        # Handle the case where there are fewer than 2 elements (e.g., return 0 or another default value)\n",
        "        return 0\n",
        "  avg = mean(numbers)\n",
        "  variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
        "  return math.sqrt(variance)\n",
        "\n",
        "\n",
        "def MeanAndStdDev(mydata):\n",
        "\tinfo = [(mean(attribute), std_dev(attribute)) for attribute in zip(*mydata)]\n",
        "\t# eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\n",
        "\t# here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\n",
        "\t# delete summaries of last class\n",
        "\tdel info[-1]\n",
        "\treturn info\n",
        "\n",
        "# find Mean and Standard Deviation under each class\n",
        "def MeanAndStdDevForClass(mydata):\n",
        "\tinfo = {}\n",
        "\tdict = groupUnderClass(mydata)\n",
        "\tfor classValue, instances in dict.items():\n",
        "\t\tinfo[classValue] = MeanAndStdDev(instances)\n",
        "\treturn info\n",
        "\n",
        "\n",
        "# Calculate Gaussian Probability Density Function\n",
        "def calculateGaussianProbability(x, mean, stdev):\n",
        "\texpo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
        "\treturn (1 / (math.sqrt(2 * math.pi) * stdev)) * expo\n",
        "\n",
        "\n",
        "# Calculate Class Probabilities\n",
        "def calculateClassProbabilities(info, test):\n",
        "    probabilities = {}\n",
        "    for classValue, classSummaries in info.items():\n",
        "        probabilities[classValue] = 1\n",
        "        for i in range(len(classSummaries)):\n",
        "            if i < len(test):  # Check if the index is within the bounds of the test list\n",
        "                mean, std_dev = classSummaries[i]\n",
        "                x = test[i]\n",
        "                probabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
        "    return probabilities\n",
        "\n",
        "\n",
        "# Make prediction - highest probability is the prediction\n",
        "def predict(info, test):\n",
        "\tprobabilities = calculateClassProbabilities(info, test)\n",
        "\tbestLabel, bestProb = None, -1\n",
        "\tfor classValue, probability in probabilities.items():\n",
        "\t\tif bestLabel is None or probability > bestProb:\n",
        "\t\t\tbestProb = probability\n",
        "\t\t\tbestLabel = classValue\n",
        "\treturn bestLabel\n",
        "\n",
        "\n",
        "# returns predictions for a set of examples\n",
        "def getPredictions(info, test):\n",
        "\tpredictions = []\n",
        "\tfor i in range(len(test)):\n",
        "\t\tresult = predict(info, test[i])\n",
        "\t\tpredictions.append(result)\n",
        "\treturn predictions\n",
        "\n",
        "# Accuracy score\n",
        "def accuracy_rate(test, predictions):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(test)):\n",
        "\t\tif test[i][-1] == predictions[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn (correct / float(len(test))) * 100.0\n",
        "\n",
        "\n",
        "# driver code\n",
        "\n",
        "# add the data path in your system\n",
        "filename = r'/content/pima-indians-diabetes.csv'\n",
        "\n",
        "\n",
        "# load the file and store it in mydata list\n",
        "mydata = csv.reader(open(filename, \"rt\"))\n",
        "mydata = list(mydata)\n",
        "mydata = encode_class(mydata)\n",
        "for i in range(len(mydata)):\n",
        "\tmydata[i] = [float(x) for x in mydata[i]]\n",
        "\n",
        "\n",
        "# split ratio = 0.7\n",
        "# 70% of data is training data and 30% is test data used for testing\n",
        "ratio = 0.7\n",
        "train_data, test_data = splitting(mydata, ratio)\n",
        "print('Total number of examples are: ', len(mydata))\n",
        "print('Out of these, training examples are: ', len(train_data))\n",
        "print(\"Test examples are: \", len(test_data))\n",
        "\n",
        "# prepare model\n",
        "info = MeanAndStdDevForClass(train_data)\n",
        "\n",
        "# test model\n",
        "predictions = getPredictions(info, test_data)\n",
        "accuracy = accuracy_rate(test_data, predictions)\n",
        "print(\"Accuracy of your model is: \", accuracy)\n"
      ]
    }
  ]
}